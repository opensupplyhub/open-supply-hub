# Generated by Django 3.2.17 on 2026-01-06

import csv
import io
import os
import sys

import boto3
from django.conf import settings
from django.db import migrations
from django.contrib.gis.geos import GEOSGeometry, MultiPolygon

csv.field_size_limit(sys.maxsize)

S3_CSV_KEY = 'data/us_county_tigerline_2021.csv'


def get_s3_client():
    '''
    Create S3 client with MinIO support for local development.
    '''
    endpoint_url = os.getenv('AWS_S3_ENDPOINT_URL')

    if endpoint_url:
        # Local development with MinIO
        return boto3.client(
            's3',
            endpoint_url=endpoint_url,
            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),
            region_name=os.getenv('AWS_REGION', 'us-east-1'),
        )
    else:
        # Production AWS S3
        return boto3.client('s3')


def download_csv_from_s3():
    '''
    Download the CSV file from S3 bucket.
    Returns the CSV content as a string.
    '''
    bucket_name = settings.AWS_STORAGE_BUCKET_NAME
    if not bucket_name:
        raise ValueError(
            'AWS_STORAGE_BUCKET_NAME is not configured. '
            'Cannot download CSV from S3.'
        )

    s3_client = get_s3_client()
    response = s3_client.get_object(Bucket=bucket_name, Key=S3_CSV_KEY)
    return response['Body'].read().decode('utf-8')


def get_csv_reader():
    '''
    Get CSV reader from S3 (or MinIO for local development).
    Returns CSV DictReader.
    '''
    csv_content = download_csv_from_s3()
    return csv.DictReader(io.StringIO(csv_content))


def clear_existing_data(apps, schema_editor):
    '''
    Clear all existing USCountyTigerline data.
    '''
    us_county_tigerline = apps.get_model('api', 'USCountyTigerline')
    us_county_tigerline.objects.all().delete()


def populate_tigerline_2021_data(apps, schema_editor):
    '''
    Clear existing data and populate the USCountyTigerline table with 2021 data from CSV file.
    Downloads from S3 or MinIO.
    In production-like environments, raises error if CSV file not found.
    Geometry data is already in EPSG:5070 (Albers Equal Area).
    '''
    us_county_tigerline = apps.get_model('api', 'USCountyTigerline')
    
    # Clear existing data first
    us_county_tigerline.objects.all().delete()

    try:
        reader = get_csv_reader()
    except Exception as e:
        env = os.getenv('DJANGO_ENV', 'Local')
        production_envs = ['Production', 'Preprod', 'Staging']

        if env not in production_envs:
            # In non-production environments, gracefully skip if CSV not found
            return

        raise Exception(
            f'Failed to download CSV file from S3: {e}. '
            f'CSV file is required in {env} environment.'
        ) from e

    tigerline_objects = []
    batch_size = 2000

    for _, row in enumerate(reader, start=1):
        geoid = row['geoid'].strip()
        name = row['name'].strip()
        geometry_wkt = row['geometry'].strip()

        if not geoid or not name or not geometry_wkt:
            continue

        # Parse geometry as (SRID 4326) and transform to (SRID 5070)
        geom = GEOSGeometry(geometry_wkt, srid=4326)
        geom.transform(5070)

        if geom.geom_type not in ("Polygon", "MultiPolygon"):
            raise ValueError(
                f'Unexpected geometry type: {geom.geom_type}'
            )

        if geom.geom_type == "Polygon":
            geom = MultiPolygon(geom, srid=5070)

        tigerline_objects.append(
            us_county_tigerline(
                geoid=geoid,
                name=name,
                geometry=geom
            )
        )

        if len(tigerline_objects) >= batch_size:
            us_county_tigerline.objects.bulk_create(
                tigerline_objects,
                batch_size=batch_size
            )
            tigerline_objects = []

    if tigerline_objects:
        us_county_tigerline.objects.bulk_create(
            tigerline_objects,
            batch_size=batch_size
        )


def reverse_populate_tigerline_2021_data(apps, schema_editor):
    '''
    Reverse operation: clear the 2021 data.
    Note: This does not restore the 2025 data.
    '''
    clear_existing_data(apps, schema_editor)


class Migration(migrations.Migration):

    dependencies = [
        ('api', '0195_add_mit_livingwage_partner_field'),
    ]

    operations = [
        migrations.RunPython(
            populate_tigerline_2021_data,
            reverse_code=reverse_populate_tigerline_2021_data
        ),
    ]

